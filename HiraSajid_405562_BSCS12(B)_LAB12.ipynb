{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating and Logging an Experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the tracking URI for MLflow to a local server running on port 5000.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulate a dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100, 1) * 10 # Random data\n",
    "y = 2.5 * X.flatten() + np.random.randn(100) * 2 # Linear relationship with noise\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and track the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/12/13 11:38:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run marvelous-ant-542 at: http://localhost:5000/#/experiments/0/runs/71697b257854461c85be74c66d5ecc3b\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    " # Define and train the model\n",
    " model = LinearRegression()\n",
    " model.fit(X_train, y_train)\n",
    " # Log parameters\n",
    " mlflow.log_param(\"fit_intercept\", model.fit_intercept)\n",
    " \n",
    " # Predict and log metrics\n",
    " y_pred = model.predict(X_test)\n",
    " rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    " mlflow.log_metric(\"rmse\", rmse)\n",
    " \n",
    " # Log the model\n",
    " mlflow.sklearn.log_model(model, \"linear_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viewing / Comparing Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "2024/12/13 11:38:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run sassy-dolphin-571 at: http://localhost:5000/#/experiments/0/runs/0c860768a5a84798b8ea5b0b62050df5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    " model = LinearRegression(fit_intercept=False)\n",
    " model.fit(X_train, y_train)\n",
    " y_pred = model.predict(X_test)\n",
    " rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    " \n",
    " mlflow.log_param(\"fit_intercept\", model.fit_intercept)\n",
    " mlflow.log_metric(\"rmse\", rmse)\n",
    " mlflow.sklearn.log_model(model, \"linear_model_no_intercept\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = pd.read_csv('data/trainingData.csv')\n",
    "testData = pd.read_csv('data/validationData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "trainData.fillna(trainData.mean(), inplace=True)\n",
    "testData.fillna(testData.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separating features and targets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = trainData.drop(['FLOOR', 'BUILDINGID', 'USERID','PHONEID','TIMESTAMP'], axis=1)\n",
    "y1_train = trainData['FLOOR']\n",
    "y2_train = trainData['BUILDINGID']\n",
    "\n",
    "X_test = testData.drop(['FLOOR', 'BUILDINGID', 'USERID','PHONEID','TIMESTAMP'], axis=1)\n",
    "y1_test = testData['FLOOR']\n",
    "y2_test = testData['BUILDINGID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training model and evaluating it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X_train, X_test, y_train, y_test, model, run_name):\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Log parameters, metrics, and model\n",
    "        mlflow.log_param(\"model\", \"RandomForest\")\n",
    "        if hasattr(model, \"get_params\"):\n",
    "            mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        # Save and log confusion matrix as a CSV\n",
    "        np.savetxt(\"confusion_matrix.csv\", conf_matrix, delimiter=\",\")\n",
    "        mlflow.log_artifact(\"confusion_matrix.csv\")\n",
    "\n",
    "        # Visualize and log confusion matrix as an image\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"confusion_matrix.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "\n",
    "        # Create an input example\n",
    "        input_example = pd.DataFrame(X_test[:5], columns=[f\"feature_{i}\" for i in range(X_test.shape[1])])\n",
    "\n",
    "        # Log the trained model with input example\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            artifact_path=\"RandomForest\",\n",
    "            input_example=input_example,\n",
    "            registered_model_name=None,  # Set a name if needed\n",
    "        )\n",
    "\n",
    "        print(f\"Run: {run_name} - Accuracy: {accuracy}\")\n",
    "        return accuracy, conf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier with default parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 1115.08it/s]\n",
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RFC Default Hyperparameters - Accuracy: 0.7632763276327633\n",
      "üèÉ View run RFC Default Hyperparameters at: http://localhost:5000/#/experiments/0/runs/292ffaa83a2a4ea5b5782373d41bd7e4\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Run 1 - Default hyperparameters\n",
    "rf_model_default = RandomForestClassifier(random_state=42)\n",
    "accuracy_default, conf_matrix_default = train_and_evaluate(X_train, X_test, y1_train, y1_test, rf_model_default, \"RFC Default Hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier with hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 547.12it/s]\n",
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: RFC Tuned Hyperparameters - Accuracy: 0.7398739873987399\n",
      "üèÉ View run RFC Tuned Hyperparameters at: http://localhost:5000/#/experiments/0/runs/d09c313fbdf84c938cc415adb5e4c163\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Run 2 - Tuned hyperparameters\n",
    "rf_model_tuned = RandomForestClassifier(n_estimators=200, max_depth=15, random_state=42)\n",
    "accuracy_tuned, conf_matrix_tuned = train_and_evaluate(X_train, X_test, y1_train, y1_test, rf_model_tuned, \"RFC Tuned Hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost Classifier with default parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:39:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 1400.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: XGB Default Hyperparameters - Accuracy: 0.630963096309631\n",
      "üèÉ View run XGB Default Hyperparameters at: http://localhost:5000/#/experiments/0/runs/898359e68c8a452b988a42af1f740bea\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Run 1 - Default hyperparameters\n",
    "xgb_model_default = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "accuracy_default, conf_matrix_default = train_and_evaluate(\n",
    "    X_train, X_test, y2_train, y2_test, xgb_model_default, \"XGB Default Hyperparameters\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost Classifier with hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:39:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\hiraa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\mlflow\\types\\utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 1750.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: XGB Tuned Hyperparameters - Accuracy: 0.630963096309631\n",
      "üèÉ View run XGB Tuned Hyperparameters at: http://localhost:5000/#/experiments/0/runs/af178c2c836e493b9dd7c3c5097e0add\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Run 2 - Tuned hyperparameters\n",
    "xgb_model_tuned = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "accuracy_tuned, conf_matrix_tuned = train_and_evaluate(\n",
    "    X_train, X_test, y2_train, y2_test, xgb_model_tuned, \"XGB Tuned Hyperparameters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data drift by introducing noise to WAP signal strengths\n",
    "def introduce_drift(data, noise_percentage=0.1):\n",
    "    drifted_data = data.copy()\n",
    "    num_drifted_rows = int(len(data) * noise_percentage)\n",
    "    drift_indices = np.random.choice(data.index, num_drifted_rows, replace=False)\n",
    "\n",
    "    for col in [col for col in data.columns if col.startswith(\"WAP\")]:\n",
    "        noise = np.random.randint(-5, 6, num_drifted_rows)\n",
    "        drifted_data.loc[drift_indices, col] += noise\n",
    "\n",
    "    return drifted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute KL divergence between two distributions\n",
    "def compute_kl_divergence(original, drifted):\n",
    "    kl_metrics = {}\n",
    "    for col in original.columns:\n",
    "        if col.startswith(\"WAP\"):\n",
    "            p, _ = np.histogram(original[col], bins=50, density=True)\n",
    "            q, _ = np.histogram(drifted[col], bins=50, density=True)\n",
    "            p += 1e-10  # To avoid division by zero\n",
    "            q += 1e-10\n",
    "            kl_metrics[col] = entropy(p, q)\n",
    "    return kl_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/13 11:43:09 INFO mlflow.tracking.fluent: Experiment with name 'data_drift_experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run data_drift_run at: http://localhost:5000/#/experiments/317304398516309058/runs/e0d84ca1ddb14b1b82a05343222227c8\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/317304398516309058\n",
      "KL divergence metrics logged in MLflow.\n"
     ]
    }
   ],
   "source": [
    "original_data = pd.read_csv(\"data/trainingData.csv\")\n",
    "# Introduce drift (adding random noise to 10% of the records)\n",
    "drifted_data = introduce_drift(original_data, noise_percentage=0.1)\n",
    "# Compute KL divergence\n",
    "kl_metrics = compute_kl_divergence(original_data, drifted_data)\n",
    "# Log results in MLflow\n",
    "mlflow.set_experiment(\"data_drift_experiment\")\n",
    "with mlflow.start_run(run_name=\"data_drift_run\"):\n",
    "    for col, kl_value in kl_metrics.items():\n",
    "        mlflow.log_metric(col, kl_value)\n",
    "print(\"KL divergence metrics logged in MLflow.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
